{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn-mnist-tensorboard.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/suhan-s/google-collab/blob/master/cnn_mnist_tensorboard.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "CEjJYZ3XDtXm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Setting Up Ngrok**"
      ]
    },
    {
      "metadata": {
        "id": "NfSrDlUxDn4v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "44355a81-5a4f-4eea-c92c-02943dc741ae"
      },
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "\n",
        "LOG_DIR = './log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-10-19 14:12:53--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.71.139.107, 52.45.84.34, 52.45.111.123, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.71.139.107|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5363700 (5.1M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \rngrok-stable-linux- 100%[===================>]   5.11M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2018-10-19 14:12:54 (39.9 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [5363700/5363700]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n",
            "http://97392c83.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dlWuvXxjEXSo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Cnn Mnist With Tensorboard Integration**"
      ]
    },
    {
      "metadata": {
        "id": "rKb_Ru1UEitb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "c60f2ef8-17c5-49c9-a3ae-73f511b26371"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import os.path\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
        "tf.reset_default_graph() \n",
        "x = tf.placeholder(tf.float32, shape=[None, 784], name='Initial_Image')\n",
        "y_ = tf.placeholder(tf.float32, shape=[None, 10], name='Output')\n",
        "x_image = tf.reshape(x, [-1, 28, 28, 1], name='Transformed_Image')\n",
        "tf.summary.image('input', x_image, 3)\n",
        "keep_prob = tf.placeholder(tf.float32, name='Dropout_Probability')\n",
        "\n",
        "with tf.name_scope(\"conv1\"):\n",
        "    conv1 = tf.layers.conv2d(x_image, 32, 5, 1, padding='SAME', activation=tf.nn.relu, name=\"conv1\")\n",
        "    maxpool1 = tf.layers.max_pooling2d(conv1, 2, 2, name=\"maxpool1\")\n",
        "\n",
        "with tf.name_scope(\"conv2\"):\n",
        "    conv2 = tf.layers.conv2d(maxpool1, 64, 5, 1, padding='SAME', activation=tf.nn.relu, name=\"conv2\")\n",
        "    maxpool2 = tf.layers.max_pooling2d(conv2, 2, 2, name=\"maxpool2\")\n",
        "\n",
        "with tf.name_scope(\"fc\"):\n",
        "    fc1 = tf.layers.flatten(maxpool2)\n",
        "    fc2 = tf.layers.dense(fc1, 1024)\n",
        "    fc3 = tf.layers.dropout(fc2, keep_prob)\n",
        "\n",
        "with tf.name_scope(\"out\"):\n",
        "    out = tf.layers.dense(fc3, 10)\n",
        "\n",
        "with tf.name_scope(\"enthropy\"):\n",
        "    cross_enthropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_, logits=out))\n",
        "    tf.summary.scalar(\"enthropy\", cross_enthropy)\n",
        "\n",
        "with tf.name_scope(\"train\"):\n",
        "    train_step = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cross_enthropy)\n",
        "\n",
        "with tf.name_scope(\"accuracy\"):\n",
        "    correct_prediction = tf.equal(tf.arg_max(out, 1), tf.arg_max(y_, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name=\"accuracy\")\n",
        "    tf.summary.scalar(\"accuracy\", accuracy)\n",
        "\n",
        "summ = tf.summary.merge_all()\n",
        "\n",
        "session = tf.InteractiveSession()\n",
        "session.run(tf.global_variables_initializer())\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "writer = tf.summary.FileWriter(LOG_DIR)\n",
        "writer.add_graph(session.graph)\n",
        "\n",
        "for steps in range(2000):\n",
        "    batch = mnist.train.next_batch(100)\n",
        "    if steps % 5 == 0:\n",
        "        [train_accuracy, s] = session.run([accuracy, summ], feed_dict={x: batch[0], y_: batch[1], keep_prob: 1})\n",
        "        writer.add_summary(s, steps)\n",
        "    if steps % 500 == 0:\n",
        "        print(\"Step %d accuracy %g\" % (steps, train_accuracy))\n",
        "        saver.save(session, os.path.join(LOG_DIR, \"model.ckpt\"), steps)  \n",
        "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
        "\n",
        "print(\"Done\")\n",
        "print(\"Traing Accuracy %g\"% accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1}))\n",
        "session.close()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "Step 0 accuracy 0.07\n",
            "Step 500 accuracy 0.97\n",
            "Step 1000 accuracy 0.95\n",
            "Step 1500 accuracy 0.98\n",
            "Done\n",
            "Traing Accuracy 0.9857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O_0BRRzcdb4U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}